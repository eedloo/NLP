{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VhMcnU0GJIs6"
      },
      "outputs": [],
      "source": [
        "# Inspired by Dr. Scannell codes\n",
        "# I trained the model with 10000 records, saved it. Then I load the trained model and evaluate test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uaIiOUG60N5h"
      },
      "outputs": [],
      "source": [
        "# Loading libraries\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_sxD3WS0a0m",
        "outputId": "c69eb8af-5c74-4985-85dc-76e19235650b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HuKeAQyogh5p",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "# Rename columns\n",
        "\n",
        "df = pd.read_csv(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/train.tsv\", sep=\"\\t\", header=None, quoting = csv.QUOTE_NONE)\n",
        "df.rename(columns={0:\"Word\", 1:\"Label\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qckrASMygh5r",
        "outputId": "e8c7d6f9-8527-4076-a090-d2d4da3d3376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Word     27\n",
              "Label     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspecting Null values on train\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W2rPqcoC00kc"
      },
      "outputs": [],
      "source": [
        "# Removing null records\n",
        "\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwKGn7Ja4gsS",
        "outputId": "8287a7d8-6be9-4ae8-b904-994c854d5073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9999973\n"
          ]
        }
      ],
      "source": [
        "# Slicing data for train\n",
        "\n",
        "print(len(df))\n",
        "df = df[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n-mVllYC1apQ"
      },
      "outputs": [],
      "source": [
        "# Getting words with labels in the shape of List of List of Tuples\n",
        "\n",
        "words = [[(df.loc[i, 'Word'], df.loc[i, 'Label'])] for i in df.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IZMz8OYa1a0T"
      },
      "outputs": [],
      "source": [
        "# list of words in data\n",
        "\n",
        "vocabs = df['Word'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nchQkb6l1a33",
        "outputId": "478a42c7-d1a9-4719-a111-02f75c728643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['N', 'S', 'U', 'H', 'T']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# list of tags\n",
        "\n",
        "tags = df['Label'].unique().tolist()\n",
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P-iUj4z6gh5r"
      },
      "outputs": [],
      "source": [
        "# pre-processing\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 60\n",
        "word2index = {w: i for i, w in enumerate(vocabs)}\n",
        "tag2index = {t: i for i, t in enumerate(tags)}\n",
        "onehot = [[word2index[w[0]] for w in s] for s in words]\n",
        "X = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(vocabs)-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tuzYdSy3gh5s"
      },
      "outputs": [],
      "source": [
        "# pre-processing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "onehot_y = [[tag2index[w[1]] for w in s] for s in words]\n",
        "y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\")\n",
        "y = to_categorical(y, num_classes=len(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AFXdVD-Rgh5s"
      },
      "outputs": [],
      "source": [
        "# runned on training process\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWfEn2Ingh5s",
        "outputId": "fd278f4e-a684-4e4a-b310-7a242281979d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 60, 50)            500000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 60, 200)          120800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 60, 5)            1005      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 621,805\n",
            "Trainable params: 621,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# building model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional \n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vocabs), output_dim=50, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
        "model.add(TimeDistributed(Dense(len(tags), activation=\"softmax\")))\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xDv80P2gh5t",
        "outputId": "6e0c8158-f974-4de8-e59e-11c837d52f99",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "507/507 [==============================] - 218s 417ms/step - loss: 0.0353 - accuracy: 0.9969 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
            "Epoch 2/5\n",
            "507/507 [==============================] - 195s 384ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
            "Epoch 3/5\n",
            "507/507 [==============================] - 194s 383ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
            "Epoch 4/5\n",
            "507/507 [==============================] - 196s 386ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
            "Epoch 5/5\n",
            "507/507 [==============================] - 194s 382ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
            "Done in: 996.841911315918 seconds\n"
          ]
        }
      ],
      "source": [
        "# fit\n",
        "import time\n",
        "start = time.time()\n",
        "n_epochs=5\n",
        "history = model.fit(X_train, y_train, batch_size=16, epochs=n_epochs, validation_split=0.1, verbose=1)\n",
        "end = time.time()\n",
        "print('Done in:', end-start, 'seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc8Ul2VBaCF",
        "outputId": "0b0d94d4-a036-49de-da7b-901aa60bd639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9989\n",
            "Testing Accuracy: 0.9982\n",
            "Done in: 11.293855428695679 seconds\n"
          ]
        }
      ],
      "source": [
        "# accuracy on train and test (splitted from data)\n",
        "\n",
        "start = time.time()\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))\n",
        "end = time.time()\n",
        "print('Done in:', end-start, 'seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XchBqZ7CQV0c"
      },
      "outputs": [],
      "source": [
        "# save trained model\n",
        "\n",
        "model.save(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/RNN_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSZQ_ZrjQs4F",
        "outputId": "55823a7c-40d0-48f7-e2b0-2be479992d7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "#Loading and run on original test dataset\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "RNN_model = load_model(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/RNN_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUq9zhkuRTSe",
        "outputId": "b6bcd8dc-d476-43d3-fbef-d7e4ec841413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 60, 50)            500000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 60, 200)          120800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 60, 5)            1005      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 621,805\n",
            "Trainable params: 621,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "RNN_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PYB6l3xezr0W"
      },
      "outputs": [],
      "source": [
        "# Load test data\n",
        "# Rename columns\n",
        "\n",
        "test = pd.read_csv(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/test.tsv\", sep=\"\\t\", header=None, quoting = csv.QUOTE_NONE)\n",
        "test.rename(columns={0:\"Word\", 1:\"Label\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s51lwohbR5DT",
        "outputId": "ccce6c7f-706d-4aad-e38d-55d65ade33d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Word     5\n",
              "Label    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspecting Null values on test\n",
        "\n",
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LqTnttrjz8lk"
      },
      "outputs": [],
      "source": [
        "# Removing null records\n",
        "\n",
        "test.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvMcSHj-6eF3",
        "outputId": "535efce9-5ee6-4c09-f747-0d83510ce250"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "999995"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ld3An1R20FdQ"
      },
      "outputs": [],
      "source": [
        "# Getting words with labels in the shape of List of List of Tuples\n",
        "\n",
        "words_test = [[(test.loc[i, 'Word'], test.loc[i, 'Label'])] for i in test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "McKPNC420OgP"
      },
      "outputs": [],
      "source": [
        "# list of words in test\n",
        "\n",
        "test_vocabs = test['Word'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5pINpUz5TAXl"
      },
      "outputs": [],
      "source": [
        "# pre-processing on test\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 60\n",
        "word2index = {w: i for i, w in enumerate(test_vocabs)}\n",
        "tag2index = {t: i for i, t in enumerate(tags)}\n",
        "onehot = [[word2index[w[0]] for w in s] for s in words_test]\n",
        "X_test = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(test_vocabs)-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Fi2KSx8uTAXm"
      },
      "outputs": [],
      "source": [
        "# pre-processing on test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "onehot_y = [[tag2index[w[1]] for w in s] for s in words_test]\n",
        "y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\")\n",
        "y_test = to_categorical(y, num_classes=len(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHVx1dxOXjKq",
        "outputId": "870e2810-611e-4ab2-aa2a-015c4b6ff20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.9976\n",
            "Done in: 943.3639192581177 seconds\n"
          ]
        }
      ],
      "source": [
        "# evaluate test dataset\n",
        "\n",
        "start = time.time()\n",
        "loss, accuracy = RNN_model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))\n",
        "end = time.time()\n",
        "print('Done in:', end-start, 'seconds')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "5da19df5fc389be667a0a925e668f06bd7bd4471eb51df3625522d83d9fd9ee9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
