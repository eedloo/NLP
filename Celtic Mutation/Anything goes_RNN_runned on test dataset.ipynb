{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VhMcnU0GJIs6"
      },
      "outputs": [],
      "source": [
        "# Inspired by Dr. Scannell codes\n",
        "# I trained the model with 10000 records, saved it, and evaluate on test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uaIiOUG60N5h"
      },
      "outputs": [],
      "source": [
        "# Loading libraries\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_sxD3WS0a0m",
        "outputId": "9b4c655a-735f-47d6-9f4b-ba56f464dd4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HuKeAQyogh5p",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "# Rename columns\n",
        "\n",
        "df = pd.read_csv(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/train.tsv\", sep=\"\\t\", header=None, quoting = csv.QUOTE_NONE)\n",
        "test = pd.read_csv(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/test.tsv\", sep=\"\\t\", header=None, quoting = csv.QUOTE_NONE)\n",
        "df.rename(columns={0:\"Word\", 1:\"Label\"}, inplace=True)\n",
        "test.rename(columns={0:\"Word\", 1:\"Label\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qckrASMygh5r",
        "outputId": "427e7ac9-3d51-4300-fcce-5d25fcf2e283"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Word     27\n",
              "Label     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspecting Null values on train\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s51lwohbR5DT",
        "outputId": "0497c343-ddc9-473a-8d98-cf78f2dc35d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Word     5\n",
              "Label    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspecting Null values on test\n",
        "\n",
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W2rPqcoC00kc"
      },
      "outputs": [],
      "source": [
        "# Removing null records\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "test.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nwKGn7Ja4gsS"
      },
      "outputs": [],
      "source": [
        "# Slicing data\n",
        "df = df[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n-mVllYC1apQ"
      },
      "outputs": [],
      "source": [
        "# Getting words with labels in the shape of List of List of Tuples\n",
        "\n",
        "words = [[(df.loc[i, 'Word'], df.loc[i, 'Label'])] for i in df.index]\n",
        "words_test = [[(test.loc[i, 'Word'], test.loc[i, 'Label'])] for i in test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IZMz8OYa1a0T"
      },
      "outputs": [],
      "source": [
        "# list of words in data\n",
        "\n",
        "vocabs = df['Word'].values.tolist()\n",
        "test_vocabs = test['Word'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nchQkb6l1a33",
        "outputId": "0f732f3c-2a33-4413-b669-1c99a0d0ecdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['N', 'S', 'U', 'H', 'T']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# list of tags\n",
        "\n",
        "tags = df['Label'].unique().tolist()\n",
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P-iUj4z6gh5r"
      },
      "outputs": [],
      "source": [
        "# pre-processing\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 60\n",
        "word2index = {w: i for i, w in enumerate(vocabs)}\n",
        "tag2index = {t: i for i, t in enumerate(tags)}\n",
        "onehot = [[word2index[w[0]] for w in s] for s in words]\n",
        "X = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(vocabs)-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tuzYdSy3gh5s"
      },
      "outputs": [],
      "source": [
        "# pre-processing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "onehot_y = [[tag2index[w[1]] for w in s] for s in words]\n",
        "y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\")\n",
        "y = to_categorical(y, num_classes=len(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AFXdVD-Rgh5s"
      },
      "outputs": [],
      "source": [
        "# runned on training process\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWfEn2Ingh5s",
        "outputId": "a4b2788f-319b-4478-f8da-bbcc1c384e2d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 60, 50)            500000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 60, 200)          120800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 60, 5)            1005      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 621,805\n",
            "Trainable params: 621,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# building model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional \n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vocabs), output_dim=50, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
        "model.add(TimeDistributed(Dense(len(tags), activation=\"softmax\")))\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xDv80P2gh5t",
        "outputId": "acd1dbca-52c1-43a2-af06-4c020d4fdc3b",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "507/507 [==============================] - 213s 403ms/step - loss: 0.0346 - accuracy: 0.9958 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
            "Epoch 2/5\n",
            "507/507 [==============================] - 205s 405ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 3/5\n",
            "507/507 [==============================] - 204s 402ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
            "Epoch 4/5\n",
            "507/507 [==============================] - 204s 403ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
            "Epoch 5/5\n",
            "507/507 [==============================] - 199s 393ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9984\n"
          ]
        }
      ],
      "source": [
        "# fit\n",
        "n_epochs=5\n",
        "history = model.fit(X_train, y_train, batch_size=16, epochs=n_epochs, validation_split=0.1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc8Ul2VBaCF",
        "outputId": "07971742-8517-43d6-b977-6205e8598212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9989\n",
            "Testing Accuracy: 0.9981\n"
          ]
        }
      ],
      "source": [
        "# accuracy on train and test (splitted from data)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XchBqZ7CQV0c"
      },
      "outputs": [],
      "source": [
        "# save trained model\n",
        "\n",
        "model.save(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSZQ_ZrjQs4F",
        "outputId": "cde608fa-65b2-4acd-8dd1-cfdb28ce8d6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "#Loading and run on test\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "rnn_model = load_model(r\"/content/drive/MyDrive/NLP/CELTIC MUTATION/model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUq9zhkuRTSe",
        "outputId": "14483c36-7c48-4524-e6dd-ba1140b859f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 60, 50)            500000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 60, 200)          120800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 60, 5)            1005      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 621,805\n",
            "Trainable params: 621,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5pINpUz5TAXl"
      },
      "outputs": [],
      "source": [
        "# pre-processing on test\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 60\n",
        "word2index = {w: i for i, w in enumerate(test_vocabs)}\n",
        "tag2index = {t: i for i, t in enumerate(tags)}\n",
        "onehot = [[word2index[w[0]] for w in s] for s in words_test]\n",
        "X_test = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(test_vocabs)-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Fi2KSx8uTAXm"
      },
      "outputs": [],
      "source": [
        "# pre-processing on test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "onehot_y = [[tag2index[w[1]] for w in s] for s in words_test]\n",
        "y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\")\n",
        "y_test = to_categorical(y, num_classes=len(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHVx1dxOXjKq",
        "outputId": "cbb79657-fa94-493f-85fe-f16e20c83245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.9976\n"
          ]
        }
      ],
      "source": [
        "# evaluate test dataset\n",
        "loss, accuracy = rnn_model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
