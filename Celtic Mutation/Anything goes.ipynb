{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Rename columns\n",
    "\n",
    "df = pd.read_csv(r\"D:\\SLU\\AI MSc\\Fall 22\\NLP\\Project 2\\train.tsv\", sep=\"\\t\", header=None, quoting = csv.QUOTE_NONE)\n",
    "df.rename(columns={0:\"Word\", 1:\"Label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word     27\n",
       "Label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting Null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing null records\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999978\n",
      "1999995\n"
     ]
    }
   ],
   "source": [
    "# test, train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting words with labels in the shape of List of List of Tuples\n",
    "\n",
    "llt = [[(train.loc[i, 'Word'], train.loc[i, 'Label'])] for i in train.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting words with labels in the shape of List of Tuples\n",
    "\n",
    "lt = [(train.loc[i, 'Word'], train.loc[i, 'Label']) for i in train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'N': 6867774, 'S': 778541, 'U': 261623, 'H': 64255, 'T': 27785})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the frequency of words\n",
    "\n",
    "fd = nltk.FreqDist(tag for [(word,tag)] in llt)\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "577\n",
      "1104\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# conditional freqency\n",
    "\n",
    "cfd = nltk.probability.ConditionalFreqDist(lt)\n",
    "print(cfd['cearta']['U'])\n",
    "print(cfd['cearta']['S'])\n",
    "print(cfd['cearta']['N'])\n",
    "print(cfd['cearta']['H'])\n",
    "print(cfd['cearta']['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words in train and test data\n",
    "\n",
    "train_words_list = train['Word'].values.tolist()\n",
    "test_words_list = test['Word'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys of words in train and test data\n",
    "\n",
    "train_justwords = nltk.FreqDist(train_words_list).keys()\n",
    "test_justwords = nltk.FreqDist(test_words_list).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on train\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(llt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction process\n",
    "\n",
    "test['Predict'] = None      # adding one new column to test data: 'Predict'\n",
    "tags_list = ['N', 'S', 'T', 'U', 'H']\n",
    "for i in test.index:\n",
    "    token = test.loc[i, 'Word']     # selecting words in test data one by one\n",
    "    prediction = unigram_tagger.tag([token])[0][1]      # tagging with nltk\n",
    "    # from my initial runs, I noticed that some of the tokens are not tagged with the algorithm.\n",
    "    # So here I check and if it is not predicted, I tagged them manually based on CFD.\n",
    "    if prediction not in tags_list:\n",
    "        tags_dist = {i:cfd[token][i] for i in tags_list}\n",
    "        prediction = max(tags_dist, key=tags_dist.get)\n",
    "    test.loc[i, 'Predict'] = prediction     # write predicted tag in the 'Predict' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079132697831744"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy\n",
    "\n",
    "len(test[test['Label'] == test['Predict']]) / len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5da19df5fc389be667a0a925e668f06bd7bd4471eb51df3625522d83d9fd9ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
