{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\SLU\\AI MSc\\Fall 22\\NLP\\Project 4\\sw-train.txt\", 'r') as f:\n",
    "    line = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractnig tokens from file\n",
    "# output: a list of all words, a list of all unique words\n",
    "\n",
    "def get_tokens(line):\n",
    "    tokens = line[0].split()\n",
    "    unique_tokens = set(tokens)\n",
    "    return tokens, unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, unique_tokens = get_tokens(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kwa', 'na', 'kusikiliza', 'ni', 'inaangalia', 'binti', 'alizonazo', 'pwani', 'maji,', 'kashachukua']\n",
      "['kwa', 'na', 'kusikiliza', 'ni', 'inaangalia', 'binti', 'alizonazo', 'pwani', 'maji,', 'kashachukua']\n"
     ]
    }
   ],
   "source": [
    "#x = tokens[5]\n",
    "print(x)\n",
    "print([*x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kwa',\n",
       " 'na',\n",
       " 'kusikiliza',\n",
       " 'ni',\n",
       " 'inaangalia',\n",
       " 'binti',\n",
       " 'alizonazo',\n",
       " 'pwani',\n",
       " 'maji,',\n",
       " 'kashachukua']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokens[:1000]\n",
    "x[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kwa'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x[0]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kw'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of n-gram is: 3\n"
     ]
    }
   ],
   "source": [
    "if len(z) < 3:\n",
    "    n = 2\n",
    "elif len(z) == 3:\n",
    "    n = 3\n",
    "elif len(z) == 4:\n",
    "    n = 4\n",
    "else:\n",
    "    n = 5\n",
    "print('order of n-gram is:', n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(token):\n",
    "    last_char = token[-1]\n",
    "    rest_char = token[:-1]\n",
    "    c_token = 0\n",
    "    c_history = 0\n",
    "    token_list = []\n",
    "    history_list = []\n",
    "    for i in range(len(x)):\n",
    "        if token in x[i]:\n",
    "            c_token += 1\n",
    "            token_list.append(x[i])\n",
    "        if token[:-1] in x[i]:\n",
    "            c_history += 1\n",
    "            history_list.append(x[i])\n",
    "    return c_token, c_history, token_list, history_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is: jjkbkjbk\n",
      "number of token in data: 0\n",
      "number of histories in data: 0\n",
      "Token list: []\n",
      "History list: []\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/1585730170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Token list:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'History list:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MLE:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_token\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "token = 'jjkbkjbk'\n",
    "c_token, c_history, token_list, history_list = count(token)\n",
    "print('Token is:', token)\n",
    "print('number of token in data:', c_token)\n",
    "print('number of histories in data:', c_history)\n",
    "print('Token list:', token_list)\n",
    "print('History list:', history_list)\n",
    "print('MLE:', c_token/c_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = -(1/len(x))*sum(np.log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, devset, and test data\n",
    "def get_data(tokens, train_rate):\n",
    "    np.random.shuffle(tokens)\n",
    "    train_size = round(len(tokens) * train_rate)\n",
    "    test_devset_size = len(tokens) - train_size\n",
    "    train = tokens[:train_size]\n",
    "    devset = tokens[train_size:round(train_size + test_devset_size/2)]\n",
    "    test = tokens[round(train_size + test_devset_size/2):]\n",
    "    return train, devset, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, devset, test = get_data(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of all tokens: 6004728\n",
      "The number of all unique tokens: 505738\n"
     ]
    }
   ],
   "source": [
    "N = len(tokens)\n",
    "V = len(unique_tokens)\n",
    "print('The number of all tokens:', N)\n",
    "print('The number of all unique tokens:', V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grams dictionary\n",
    "# output: a dictionary with number of charachters as keys and a list of same lengths tokens as values\n",
    "\n",
    "def get_gram(tokens):\n",
    "    longest_gram = max(tokens, key=len)\n",
    "    grams = {}\n",
    "    n = len(longest_gram)\n",
    "    while n > 0:\n",
    "        list_of_words = []\n",
    "        for i in range(len(tokens)):\n",
    "            if len(tokens[i]) == n:\n",
    "                list_of_words.append(tokens[i])\n",
    "        if len(list_of_words) > 0:\n",
    "            grams[n] = list_of_words\n",
    "        n -= 1\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grams = get_gram(train)\n",
    "devset_grams = get_gram(devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([143, 133, 130, 118, 100, 95, 90, 87, 85, 79, 72, 71, 70, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kwakuzingatiamaelekezoyatumemaalumiliyochunguzadosarizilizojitokezakwenyematokeoyamtihaniwakidatocha']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grams[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([93, 88, 67, 64, 61, 56, 55, 53, 46, 42, 40, 39, 38, 37, 36, 35, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset_grams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = devset_grams[56][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kiroho', 'kiuchumi', 'kijamii', 'kiafya', 'kimwili', 'kibiashara', 'kindoa']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9886d89d00ab45e82c8ee75015344ff9f539db9369165debfcbb1d4785acc62d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
